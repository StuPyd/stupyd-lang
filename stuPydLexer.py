# Generated from D:/stuPYd/stupyd_demo_4\stuPyd.g4 by ANTLR 4.7
from antlr4 import *
from io import StringIO
from typing.io import TextIO
import sys


from stuPydParser import stuPydParser
from antlr4.Token import CommonToken


def serializedATN():
    with StringIO() as buf:
        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\2*")
        buf.write("\u0158\b\1\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7")
        buf.write("\t\7\4\b\t\b\4\t\t\t\4\n\t\n\4\13\t\13\4\f\t\f\4\r\t\r")
        buf.write("\4\16\t\16\4\17\t\17\4\20\t\20\4\21\t\21\4\22\t\22\4\23")
        buf.write("\t\23\4\24\t\24\4\25\t\25\4\26\t\26\4\27\t\27\4\30\t\30")
        buf.write("\4\31\t\31\4\32\t\32\4\33\t\33\4\34\t\34\4\35\t\35\4\36")
        buf.write("\t\36\4\37\t\37\4 \t \4!\t!\4\"\t\"\4#\t#\4$\t$\4%\t%")
        buf.write("\4&\t&\4\'\t\'\4(\t(\4)\t)\4*\t*\4+\t+\4,\t,\4-\t-\4.")
        buf.write("\t.\4/\t/\4\60\t\60\3\2\3\2\3\2\3\2\3\2\3\2\3\2\3\2\3")
        buf.write("\2\3\2\3\2\3\3\3\3\3\4\3\4\3\4\3\5\3\5\3\5\3\5\3\6\3\6")
        buf.write("\3\6\3\6\3\6\3\7\3\7\3\7\3\7\3\7\3\7\3\7\3\b\3\b\3\b\3")
        buf.write("\b\3\b\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\n\3\n\3\13\3\13\3")
        buf.write("\f\3\f\3\r\3\r\3\16\3\16\3\17\3\17\3\20\3\20\3\21\3\21")
        buf.write("\3\22\3\22\3\23\3\23\3\24\3\24\3\25\3\25\3\26\3\26\3\27")
        buf.write("\3\27\3\30\3\30\3\31\3\31\3\31\3\32\3\32\3\32\3\33\3\33")
        buf.write("\3\34\3\34\3\34\3\34\3\34\3\35\3\35\3\35\3\35\3\35\3\35")
        buf.write("\3\36\3\36\3\36\3\36\3\36\3\36\3\37\3\37\3 \3 \3 \3!\3")
        buf.write("!\3!\3!\3!\3\"\3\"\5\"\u00d1\n\"\3#\6#\u00d4\n#\r#\16")
        buf.write("#\u00d5\3$\3$\3$\5$\u00db\n$\3$\3$\5$\u00df\n$\3$\5$\u00e2")
        buf.write("\n$\5$\u00e4\n$\3$\3$\3%\3%\6%\u00ea\n%\r%\16%\u00eb\3")
        buf.write("%\3%\3&\3&\7&\u00f2\n&\f&\16&\u00f5\13&\3\'\6\'\u00f8")
        buf.write("\n\'\r\'\16\'\u00f9\3(\6(\u00fd\n(\r(\16(\u00fe\3(\3(")
        buf.write("\7(\u0103\n(\f(\16(\u0106\13(\3(\5(\u0109\n(\3(\3(\6(")
        buf.write("\u010d\n(\r(\16(\u010e\3(\5(\u0112\n(\3(\6(\u0115\n(\r")
        buf.write("(\16(\u0116\3(\5(\u011a\n(\3)\3)\3)\7)\u011f\n)\f)\16")
        buf.write(")\u0122\13)\3)\3)\3*\3*\3*\5*\u0129\n*\3*\3*\3+\3+\3+")
        buf.write("\3+\7+\u0131\n+\f+\16+\u0134\13+\3,\3,\5,\u0138\n,\3,")
        buf.write("\6,\u013b\n,\r,\16,\u013c\3-\3-\3.\3.\3.\3.\5.\u0145\n")
        buf.write(".\3/\3/\3/\3/\3/\3/\3/\3/\3/\5/\u0150\n/\3\60\3\60\3\60")
        buf.write("\3\60\3\60\3\60\3\60\2\2\61\3\3\5\4\7\5\t\6\13\7\r\b\17")
        buf.write("\t\21\n\23\13\25\f\27\r\31\16\33\17\35\20\37\21!\22#\23")
        buf.write("%\24\'\25)\26+\27-\30/\31\61\32\63\33\65\34\67\359\36")
        buf.write(";\37= ?!A\"C#E\2G$I%K&M\'O(Q)S*U\2W\2Y\2[\2]\2_\2\3\2")
        buf.write("\f\4\2\13\13\"\"\5\2C\\aac|\6\2\62;C\\aac|\4\2$$^^\4\2")
        buf.write("))^^\4\2\f\f\16\17\4\2GGgg\4\2--//\5\2\62;CHch\n\2$$)")
        buf.write(")^^ddhhppttvv\2\u016c\2\3\3\2\2\2\2\5\3\2\2\2\2\7\3\2")
        buf.write("\2\2\2\t\3\2\2\2\2\13\3\2\2\2\2\r\3\2\2\2\2\17\3\2\2\2")
        buf.write("\2\21\3\2\2\2\2\23\3\2\2\2\2\25\3\2\2\2\2\27\3\2\2\2\2")
        buf.write("\31\3\2\2\2\2\33\3\2\2\2\2\35\3\2\2\2\2\37\3\2\2\2\2!")
        buf.write("\3\2\2\2\2#\3\2\2\2\2%\3\2\2\2\2\'\3\2\2\2\2)\3\2\2\2")
        buf.write("\2+\3\2\2\2\2-\3\2\2\2\2/\3\2\2\2\2\61\3\2\2\2\2\63\3")
        buf.write("\2\2\2\2\65\3\2\2\2\2\67\3\2\2\2\29\3\2\2\2\2;\3\2\2\2")
        buf.write("\2=\3\2\2\2\2?\3\2\2\2\2A\3\2\2\2\2C\3\2\2\2\2G\3\2\2")
        buf.write("\2\2I\3\2\2\2\2K\3\2\2\2\2M\3\2\2\2\2O\3\2\2\2\2Q\3\2")
        buf.write("\2\2\2S\3\2\2\2\3a\3\2\2\2\5l\3\2\2\2\7n\3\2\2\2\tq\3")
        buf.write("\2\2\2\13u\3\2\2\2\rz\3\2\2\2\17\u0081\3\2\2\2\21\u0086")
        buf.write("\3\2\2\2\23\u008d\3\2\2\2\25\u008f\3\2\2\2\27\u0091\3")
        buf.write("\2\2\2\31\u0093\3\2\2\2\33\u0095\3\2\2\2\35\u0097\3\2")
        buf.write("\2\2\37\u0099\3\2\2\2!\u009b\3\2\2\2#\u009d\3\2\2\2%\u009f")
        buf.write("\3\2\2\2\'\u00a1\3\2\2\2)\u00a3\3\2\2\2+\u00a5\3\2\2\2")
        buf.write("-\u00a7\3\2\2\2/\u00a9\3\2\2\2\61\u00ab\3\2\2\2\63\u00ae")
        buf.write("\3\2\2\2\65\u00b1\3\2\2\2\67\u00b3\3\2\2\29\u00b8\3\2")
        buf.write("\2\2;\u00be\3\2\2\2=\u00c4\3\2\2\2?\u00c6\3\2\2\2A\u00c9")
        buf.write("\3\2\2\2C\u00d0\3\2\2\2E\u00d3\3\2\2\2G\u00e3\3\2\2\2")
        buf.write("I\u00e9\3\2\2\2K\u00ef\3\2\2\2M\u00f7\3\2\2\2O\u0119\3")
        buf.write("\2\2\2Q\u011b\3\2\2\2S\u0125\3\2\2\2U\u012c\3\2\2\2W\u0135")
        buf.write("\3\2\2\2Y\u013e\3\2\2\2[\u0144\3\2\2\2]\u014f\3\2\2\2")
        buf.write("_\u0151\3\2\2\2ab\7%\2\2bc\7F\2\2cd\7G\2\2de\7E\2\2ef")
        buf.write("\7Q\2\2fg\7O\2\2gh\7R\2\2hi\7K\2\2ij\7N\2\2jk\7G\2\2k")
        buf.write("\4\3\2\2\2lm\7=\2\2m\6\3\2\2\2no\7/\2\2op\7@\2\2p\b\3")
        buf.write("\2\2\2qr\7p\2\2rs\7w\2\2st\7o\2\2t\n\3\2\2\2uv\7d\2\2")
        buf.write("vw\7q\2\2wx\7q\2\2xy\7n\2\2y\f\3\2\2\2z{\7u\2\2{|\7v\2")
        buf.write("\2|}\7t\2\2}~\7k\2\2~\177\7p\2\2\177\u0080\7i\2\2\u0080")
        buf.write("\16\3\2\2\2\u0081\u0082\7x\2\2\u0082\u0083\7q\2\2\u0083")
        buf.write("\u0084\7k\2\2\u0084\u0085\7f\2\2\u0085\20\3\2\2\2\u0086")
        buf.write("\u0087\7u\2\2\u0087\u0088\7v\2\2\u0088\u0089\7t\2\2\u0089")
        buf.write("\u008a\7w\2\2\u008a\u008b\7e\2\2\u008b\u008c\7v\2\2\u008c")
        buf.write("\22\3\2\2\2\u008d\u008e\7.\2\2\u008e\24\3\2\2\2\u008f")
        buf.write("\u0090\7]\2\2\u0090\26\3\2\2\2\u0091\u0092\7_\2\2\u0092")
        buf.write("\30\3\2\2\2\u0093\u0094\7-\2\2\u0094\32\3\2\2\2\u0095")
        buf.write("\u0096\7/\2\2\u0096\34\3\2\2\2\u0097\u0098\7,\2\2\u0098")
        buf.write("\36\3\2\2\2\u0099\u009a\7\61\2\2\u009a \3\2\2\2\u009b")
        buf.write("\u009c\7`\2\2\u009c\"\3\2\2\2\u009d\u009e\7*\2\2\u009e")
        buf.write("$\3\2\2\2\u009f\u00a0\7+\2\2\u00a0&\3\2\2\2\u00a1\u00a2")
        buf.write("\7~\2\2\u00a2(\3\2\2\2\u00a3\u00a4\7(\2\2\u00a4*\3\2\2")
        buf.write("\2\u00a5\u00a6\7?\2\2\u00a6,\3\2\2\2\u00a7\u00a8\7@\2")
        buf.write("\2\u00a8.\3\2\2\2\u00a9\u00aa\7>\2\2\u00aa\60\3\2\2\2")
        buf.write("\u00ab\u00ac\7@\2\2\u00ac\u00ad\7?\2\2\u00ad\62\3\2\2")
        buf.write("\2\u00ae\u00af\7>\2\2\u00af\u00b0\7?\2\2\u00b0\64\3\2")
        buf.write("\2\2\u00b1\u00b2\7#\2\2\u00b2\66\3\2\2\2\u00b3\u00b4\7")
        buf.write("V\2\2\u00b4\u00b5\7T\2\2\u00b5\u00b6\7W\2\2\u00b6\u00b7")
        buf.write("\7G\2\2\u00b78\3\2\2\2\u00b8\u00b9\7H\2\2\u00b9\u00ba")
        buf.write("\7C\2\2\u00ba\u00bb\7N\2\2\u00bb\u00bc\7U\2\2\u00bc\u00bd")
        buf.write("\7G\2\2\u00bd:\3\2\2\2\u00be\u00bf\7y\2\2\u00bf\u00c0")
        buf.write("\7j\2\2\u00c0\u00c1\7k\2\2\u00c1\u00c2\7n\2\2\u00c2\u00c3")
        buf.write("\7g\2\2\u00c3<\3\2\2\2\u00c4\u00c5\7<\2\2\u00c5>\3\2\2")
        buf.write("\2\u00c6\u00c7\7k\2\2\u00c7\u00c8\7h\2\2\u00c8@\3\2\2")
        buf.write("\2\u00c9\u00ca\7g\2\2\u00ca\u00cb\7n\2\2\u00cb\u00cc\7")
        buf.write("u\2\2\u00cc\u00cd\7g\2\2\u00cdB\3\2\2\2\u00ce\u00d1\5")
        buf.write("M\'\2\u00cf\u00d1\5O(\2\u00d0\u00ce\3\2\2\2\u00d0\u00cf")
        buf.write("\3\2\2\2\u00d1D\3\2\2\2\u00d2\u00d4\t\2\2\2\u00d3\u00d2")
        buf.write("\3\2\2\2\u00d4\u00d5\3\2\2\2\u00d5\u00d3\3\2\2\2\u00d5")
        buf.write("\u00d6\3\2\2\2\u00d6F\3\2\2\2\u00d7\u00d8\6$\2\2\u00d8")
        buf.write("\u00e4\5E#\2\u00d9\u00db\7\17\2\2\u00da\u00d9\3\2\2\2")
        buf.write("\u00da\u00db\3\2\2\2\u00db\u00dc\3\2\2\2\u00dc\u00df\7")
        buf.write("\f\2\2\u00dd\u00df\7\17\2\2\u00de\u00da\3\2\2\2\u00de")
        buf.write("\u00dd\3\2\2\2\u00df\u00e1\3\2\2\2\u00e0\u00e2\5E#\2\u00e1")
        buf.write("\u00e0\3\2\2\2\u00e1\u00e2\3\2\2\2\u00e2\u00e4\3\2\2\2")
        buf.write("\u00e3\u00d7\3\2\2\2\u00e3\u00de\3\2\2\2\u00e4\u00e5\3")
        buf.write("\2\2\2\u00e5\u00e6\b$\2\2\u00e6H\3\2\2\2\u00e7\u00ea\5")
        buf.write("E#\2\u00e8\u00ea\5U+\2\u00e9\u00e7\3\2\2\2\u00e9\u00e8")
        buf.write("\3\2\2\2\u00ea\u00eb\3\2\2\2\u00eb\u00e9\3\2\2\2\u00eb")
        buf.write("\u00ec\3\2\2\2\u00ec\u00ed\3\2\2\2\u00ed\u00ee\b%\3\2")
        buf.write("\u00eeJ\3\2\2\2\u00ef\u00f3\t\3\2\2\u00f0\u00f2\t\4\2")
        buf.write("\2\u00f1\u00f0\3\2\2\2\u00f2\u00f5\3\2\2\2\u00f3\u00f1")
        buf.write("\3\2\2\2\u00f3\u00f4\3\2\2\2\u00f4L\3\2\2\2\u00f5\u00f3")
        buf.write("\3\2\2\2\u00f6\u00f8\4\62;\2\u00f7\u00f6\3\2\2\2\u00f8")
        buf.write("\u00f9\3\2\2\2\u00f9\u00f7\3\2\2\2\u00f9\u00fa\3\2\2\2")
        buf.write("\u00faN\3\2\2\2\u00fb\u00fd\4\62;\2\u00fc\u00fb\3\2\2")
        buf.write("\2\u00fd\u00fe\3\2\2\2\u00fe\u00fc\3\2\2\2\u00fe\u00ff")
        buf.write("\3\2\2\2\u00ff\u0100\3\2\2\2\u0100\u0104\7\60\2\2\u0101")
        buf.write("\u0103\4\62;\2\u0102\u0101\3\2\2\2\u0103\u0106\3\2\2\2")
        buf.write("\u0104\u0102\3\2\2\2\u0104\u0105\3\2\2\2\u0105\u0108\3")
        buf.write("\2\2\2\u0106\u0104\3\2\2\2\u0107\u0109\5W,\2\u0108\u0107")
        buf.write("\3\2\2\2\u0108\u0109\3\2\2\2\u0109\u011a\3\2\2\2\u010a")
        buf.write("\u010c\7\60\2\2\u010b\u010d\4\62;\2\u010c\u010b\3\2\2")
        buf.write("\2\u010d\u010e\3\2\2\2\u010e\u010c\3\2\2\2\u010e\u010f")
        buf.write("\3\2\2\2\u010f\u0111\3\2\2\2\u0110\u0112\5W,\2\u0111\u0110")
        buf.write("\3\2\2\2\u0111\u0112\3\2\2\2\u0112\u011a\3\2\2\2\u0113")
        buf.write("\u0115\4\62;\2\u0114\u0113\3\2\2\2\u0115\u0116\3\2\2\2")
        buf.write("\u0116\u0114\3\2\2\2\u0116\u0117\3\2\2\2\u0117\u0118\3")
        buf.write("\2\2\2\u0118\u011a\5W,\2\u0119\u00fc\3\2\2\2\u0119\u010a")
        buf.write("\3\2\2\2\u0119\u0114\3\2\2\2\u011aP\3\2\2\2\u011b\u0120")
        buf.write("\7$\2\2\u011c\u011f\5[.\2\u011d\u011f\n\5\2\2\u011e\u011c")
        buf.write("\3\2\2\2\u011e\u011d\3\2\2\2\u011f\u0122\3\2\2\2\u0120")
        buf.write("\u011e\3\2\2\2\u0120\u0121\3\2\2\2\u0121\u0123\3\2\2\2")
        buf.write("\u0122\u0120\3\2\2\2\u0123\u0124\7$\2\2\u0124R\3\2\2\2")
        buf.write("\u0125\u0128\7)\2\2\u0126\u0129\5[.\2\u0127\u0129\n\6")
        buf.write("\2\2\u0128\u0126\3\2\2\2\u0128\u0127\3\2\2\2\u0129\u012a")
        buf.write("\3\2\2\2\u012a\u012b\7)\2\2\u012bT\3\2\2\2\u012c\u012d")
        buf.write("\7\61\2\2\u012d\u012e\7\61\2\2\u012e\u0132\3\2\2\2\u012f")
        buf.write("\u0131\n\7\2\2\u0130\u012f\3\2\2\2\u0131\u0134\3\2\2\2")
        buf.write("\u0132\u0130\3\2\2\2\u0132\u0133\3\2\2\2\u0133V\3\2\2")
        buf.write("\2\u0134\u0132\3\2\2\2\u0135\u0137\t\b\2\2\u0136\u0138")
        buf.write("\t\t\2\2\u0137\u0136\3\2\2\2\u0137\u0138\3\2\2\2\u0138")
        buf.write("\u013a\3\2\2\2\u0139\u013b\4\62;\2\u013a\u0139\3\2\2\2")
        buf.write("\u013b\u013c\3\2\2\2\u013c\u013a\3\2\2\2\u013c\u013d\3")
        buf.write("\2\2\2\u013dX\3\2\2\2\u013e\u013f\t\n\2\2\u013fZ\3\2\2")
        buf.write("\2\u0140\u0141\7^\2\2\u0141\u0145\t\13\2\2\u0142\u0145")
        buf.write("\5_\60\2\u0143\u0145\5]/\2\u0144\u0140\3\2\2\2\u0144\u0142")
        buf.write("\3\2\2\2\u0144\u0143\3\2\2\2\u0145\\\3\2\2\2\u0146\u0147")
        buf.write("\7^\2\2\u0147\u0148\4\62\65\2\u0148\u0149\4\629\2\u0149")
        buf.write("\u0150\4\629\2\u014a\u014b\7^\2\2\u014b\u014c\4\629\2")
        buf.write("\u014c\u0150\4\629\2\u014d\u014e\7^\2\2\u014e\u0150\4")
        buf.write("\629\2\u014f\u0146\3\2\2\2\u014f\u014a\3\2\2\2\u014f\u014d")
        buf.write("\3\2\2\2\u0150^\3\2\2\2\u0151\u0152\7^\2\2\u0152\u0153")
        buf.write("\7w\2\2\u0153\u0154\5Y-\2\u0154\u0155\5Y-\2\u0155\u0156")
        buf.write("\5Y-\2\u0156\u0157\5Y-\2\u0157`\3\2\2\2\34\2\u00d0\u00d5")
        buf.write("\u00da\u00de\u00e1\u00e3\u00e9\u00eb\u00f3\u00f9\u00fe")
        buf.write("\u0104\u0108\u010e\u0111\u0116\u0119\u011e\u0120\u0128")
        buf.write("\u0132\u0137\u013c\u0144\u014f\4\3$\2\b\2\2")
        return buf.getvalue()


class stuPydLexer(Lexer):

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]

    T__0 = 1
    T__1 = 2
    T__2 = 3
    T__3 = 4
    T__4 = 5
    T__5 = 6
    T__6 = 7
    T__7 = 8
    T__8 = 9
    T__9 = 10
    T__10 = 11
    T__11 = 12
    T__12 = 13
    T__13 = 14
    T__14 = 15
    T__15 = 16
    T__16 = 17
    T__17 = 18
    T__18 = 19
    T__19 = 20
    T__20 = 21
    T__21 = 22
    T__22 = 23
    T__23 = 24
    T__24 = 25
    T__25 = 26
    T__26 = 27
    T__27 = 28
    T__28 = 29
    T__29 = 30
    T__30 = 31
    T__31 = 32
    NUMBER = 33
    NEWLINE = 34
    BLANK = 35
    ID = 36
    INT = 37
    FLOAT = 38
    STRING = 39
    CHAR = 40

    channelNames = [ u"DEFAULT_TOKEN_CHANNEL", u"HIDDEN" ]

    modeNames = [ "DEFAULT_MODE" ]

    literalNames = [ "<INVALID>",
            "'#DECOMPILE'", "';'", "'->'", "'num'", "'bool'", "'string'", 
            "'void'", "'struct'", "','", "'['", "']'", "'+'", "'-'", "'*'", 
            "'/'", "'^'", "'('", "')'", "'|'", "'&'", "'='", "'>'", "'<'", 
            "'>='", "'<='", "'!'", "'TRUE'", "'FALSE'", "'while'", "':'", 
            "'if'", "'else'" ]

    symbolicNames = [ "<INVALID>",
            "NUMBER", "NEWLINE", "BLANK", "ID", "INT", "FLOAT", "STRING", 
            "CHAR" ]

    ruleNames = [ "T__0", "T__1", "T__2", "T__3", "T__4", "T__5", "T__6", 
                  "T__7", "T__8", "T__9", "T__10", "T__11", "T__12", "T__13", 
                  "T__14", "T__15", "T__16", "T__17", "T__18", "T__19", 
                  "T__20", "T__21", "T__22", "T__23", "T__24", "T__25", 
                  "T__26", "T__27", "T__28", "T__29", "T__30", "T__31", 
                  "NUMBER", "SPACES", "NEWLINE", "BLANK", "ID", "INT", "FLOAT", 
                  "STRING", "CHAR", "COMMENT", "EXPONENT", "HEX_DIGIT", 
                  "ESC_SEQ", "OCTAL_ESC", "UNICODE_ESC" ]

    grammarFileName = "stuPyd.g4"

    def __init__(self, input=None, output:TextIO = sys.stdout):
        super().__init__(input, output)
        self.checkVersion("4.7")
        self._interp = LexerATNSimulator(self, self.atn, self.decisionsToDFA, PredictionContextCache())
        self._actions = None
        self._predicates = None


        self.lastToken = None
        self.tokens = []
        self.indentStack = []

    def emit(self,t=None):
        if t == None :
            s = self._factory.create(self._tokenFactorySourcePair, self._type, self._text, self._channel, self._tokenStartCharIndex,
                                     self.getCharIndex()-1, self._tokenStartLine, self._tokenStartColumn)
            self.emitToken(s)
            #print(s)
            self.tokens.append(s)
            return s
        else:
            self.emitToken(t)
            self.tokens.append(t)
            #print(t)
            return t

    def commonToken(self,type,text):
        stop = self.getCharIndex()-1
        if len(text)==0 :
            start = stop
        else:
            start = stop - len(text)+1
        return CommonToken(self._tokenFactorySourcePair,type,self.DEFAULT_TOKEN_CHANNEL,start,stop)

    def createDedent(self):
        dedent = self.commonToken(stuPydParser.DEDENT,'')
        dedent.line = self.lastToken.line
        return dedent

    @staticmethod
    def getIndentationCount(spaces):
        count = 0
        for ch in spaces:
            if ch == '\t':
                count +=( 4 - (count%4))
            elif ch == ' ':
                count += 1
            else :
                pass
        # print(count)
        return count

    def nextToken(self):
        # Check if the end-of-file is ahead and there are still some DEDENTS expected
        if(self._input.LA(1)==Token.EOF and len(self.indentStack)!=0):
            # Remove ant trailing EOF tokens from our buffer
            i = len(self.tokens)-1
            while i>= 0 :
                if(self.tokens[i].type==Token.EOF):
                    self.tokens.pop(i)
                i-=1
            # First emit an extra line break that serves as the end of the stmt
            self.emit(self.commonToken(stuPydParser.NEWLINE,'\n'))
            # Now emit as much DEDENT tokens as needed
            while len(self.indentStack)!=0 :
                self.emit(self.createDedent())
                self.indentStack.pop()
            # put the EOF back on the token stream .
            self.emit(self.commonToken(stuPydParser.EOF,'<EOF>'))
        next = super().nextToken()
        if (next.channel == Token.DEFAULT_CHANNEL):
            # Keep track of the last token on the default channel
            self.lastToken = next
        if len(self.tokens) == 0 :
            # print(next)
            return next
        else :
            temp = self.tokens[0]
            self.tokens.pop(0)
            #print(temp)
            return temp

    def atStartOfInput(self):
        if super().getCharIndex()==0 and super().line==1 :
            # print('True')
            return True
        else:
            # print('False')
            return False


    def action(self, localctx:RuleContext, ruleIndex:int, actionIndex:int):
    	if self._actions is None:
    		actions = dict()
    		actions[34] = self.NEWLINE_action 
    		self._actions = actions
    	action = self._actions.get(ruleIndex, None)
    	if action is not None:
    		action(localctx, actionIndex)
    	else:
    		raise Exception("No registered action for:" + str(ruleIndex))

    def NEWLINE_action(self, localctx:RuleContext , actionIndex:int):
        if actionIndex == 0:

                    newLine = self.text
                    for i in newLine :
                        if i == '\r' or i == '\n' or i == '\f':
                            pass
                        else:
                            newLine.replace(str(i),'')

                    spaces = self.text.replace('\r','')
                    spaces = self.text.replace('\n','')
                    spaces = self.text.replace('\f','')

                    next = self._input.LA(1)

                    if(next=='\r' or next == '\n' or next == '\f' or next == '<EOF>'):
                        self.skip()
                    else:
                        self.emit(self.commonToken(self.NEWLINE,newLine))
                        indent = self.getIndentationCount(spaces)
                        previous = 0
                        if len(self.indentStack) != 0 :
                            previous = self.indentStack.pop()
                            self.indentStack.append(previous)
                            # it is equal to indentStack.peek()
                        if indent==previous :
                            # skip indents of the same size as the present indent-size
                            self.skip()
                        elif indent > previous :
                            self.indentStack.append(indent)
                            self.emit(self.commonToken(stuPydParser.INDENT,spaces))
                        else:
                            # Possibly emit more than 1 DEDENT token
                            while len(self.indentStack)!=0 and self.indentStack[len(self.indentStack)-1]>indent:
                                self.emit(self.createDedent())
                                self.indentStack.pop()
               
     

    def sempred(self, localctx:RuleContext, ruleIndex:int, predIndex:int):
        if self._predicates is None:
            preds = dict()
            preds[34] = self.NEWLINE_sempred
            self._predicates = preds
        pred = self._predicates.get(ruleIndex, None)
        if pred is not None:
            return pred(localctx, predIndex)
        else:
            raise Exception("No registered predicate for:" + str(ruleIndex))

    def NEWLINE_sempred(self, localctx:RuleContext, predIndex:int):
            if predIndex == 0:
                return self.atStartOfInput()
         


